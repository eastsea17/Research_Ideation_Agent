title,abstract,url,publication_year,authors,institutions
Exploring Material Design Space with a Deep-Learning Guided Genetic Algorithm,"Designing complex, dynamic yet multi-functional materials and devices is challenging because the design spaces for these materials have numerous interdependent and often conflicting constraints. Taking inspiration from advances in artificial intelligence and their applications in material discovery, we propose a computational method for designing metamorphic DNA-co-polymerized hydrogel structures. The method consists of a coarse-grained simulation and a deep learning-guided optimization system for exploring the immense design space of these structures. Here, we develop a simple numeric simulation of DNA-co-polymerized hydrogel shape change and seek to find designs for structured hydrogels that can fold into the shapes of different Arabic numerals in different actuation states. We train a convolutional neural network to classify and score the geometric outputs of the coarse-grained simulation to provide autonomous feedback for design optimization. We then construct a genetic algorithm that generates and selects large batches of material designs that compete with one another to evolve and converge on optimal objective-matching designs. We show that we are able to explore the large design space and learn important parameters and traits. We identify vital relationships between the material scale size and the range of shape change that can be achieved by individual domains and we elucidate trade-offs between different design parameters. Finally, we discover material designs capable of transforming into multiple different digits in different actuation states.",https://openalex.org/W2964121744,2022,Diederik P. Kingma; Jimmy Ba,
Deep Residual Learning for Image Recognition,"Actualmente diversas investigaciones se han enfocado en analizar a partir de videos de alta velocidad, características de las descargas eléctricas atmosféricas con el fin de adquirir mejor comprensión del fenómeno, que conlleva entre otros aspectos el desarrollo de sistemas de protección robustos. La mayoría de las investigaciones han requerido de un observador que ante el suceso del evento provea un disparo manual a la cámara permitiendo almacenar la información visual del fenómeno. Por tanto, este trabajo se orientó en proponer una metodología para la detección de las descargas utilizando dos implementaciones basadas en procesamiento de señales y visión computacional, con el propósito que el sistema autónomamente sea el que suministre el disparo, apartando al observador de la realización de esta tarea. El sistema de detección basado en técnicas de procesamiento de imágenes requirió la adecuación de métodos de segmentación, representación, descripción y clasificación. El algoritmo de reconocimiento con visión computacional se implementó mediante la red neuronal convolucional EfficientNetB4. Fuera de línea, las técnicas basadas en procesamiento de imágenes suministraron una precisión del 81.81%, mientras que haciendo uso de visión computacional la precisión fue de 71.63%. Con el objeto de evaluar el desempeño en tiempo real, las técnicas de procesamiento se adaptaron en un ordenador de placa reducida correspondiente a la Raspberry Pi 3 modelo B+ obteniéndose una precisión de 86.95%. Adicionalmente, se evaluó la característica de multiplicidad la cual corresponde al número de descargas subsecuentes presentes en el canal de la descarga logrando una precisión de 66.66%. (Texto tomado de la fuente)",https://openalex.org/W2194775991,2016,Kaiming He; Xiangyu Zhang; Shaoqing Ren,Microsoft Research (United Kingdom)
Deep Learning,"Deep learning is a form of machine learning that enables computers to learn from experience and understand the world in terms of a hierarchy of concepts. Because the computer gathers knowledge from experience, there is no need for a human computer operator to formally specify all the knowledge that the computer needs. The hierarchy of concepts allows the computer to learn complicated concepts by building them out of simpler ones; a graph of these hierarchies would be many layers deep. This book introduces a broad range of topics in deep learning. The text offers mathematical and conceptual background, covering relevant concepts in linear algebra, probability theory and information theory, numerical computation, and machine learning. It describes deep learning techniques used by practitioners in industry, including deep feedforward networks, regularization, optimization algorithms, convolutional networks, sequence modeling, and practical methodology; and it surveys such applications as natural language processing, speech recognition, computer vision, online recommendation systems, bioinformatics, and videogames. Finally, the book offers research perspectives, covering such theoretical topics as linear factor models, autoencoders, representation learning, structured probabilistic models, Monte Carlo methods, the partition function, approximate inference, and deep generative models. Deep Learning can be used by undergraduate or graduate students planning careers in either industry or research, and by software engineers who want to begin using deep learning in their products or platforms. A website offers supplementary material for both readers and instructors.",https://openalex.org/W2557283755,2016,Ian Goodfellow; Yoshua Bengio; Aaron Courville,Google (United States); Université de Montréal
Xception: Deep Learning with Depthwise Separable Convolutions,"We present an interpretation of Inception modules in convolutional neural networks as being an intermediate step in-between regular convolution and the depthwise separable convolution operation (a depthwise convolution followed by a pointwise convolution). In this light, a depthwise separable convolution can be understood as an Inception module with a maximally large number of towers. This observation leads us to propose a novel deep convolutional neural network architecture inspired by Inception, where Inception modules have been replaced with depthwise separable convolutions. We show that this architecture, dubbed Xception, slightly outperforms Inception V3 on the ImageNet dataset (which Inception V3 was designed for), and significantly outperforms Inception V3 on a larger image classification dataset comprising 350 million images and 17,000 classes. Since the Xception architecture has the same number of parameters as Inception V3, the performance gains are not due to increased capacity but rather to a more efficient use of model parameters.",https://openalex.org/W2531409750,2017,François Chollet,Google (United States)
"PyTorch: An Imperative Style, High-Performance Deep Learning Library","Deep learning frameworks have often focused on either usability or speed, but not both. PyTorch is a machine learning library that shows that these two goals are in fact compatible: it provides an imperative and Pythonic programming style that supports code as a model, makes debugging easy and is consistent with other popular scientific computing libraries, while remaining efficient and supporting hardware accelerators such as GPUs. In this paper, we detail the principles that drove the implementation of PyTorch and how they are reflected in its architecture. We emphasize that every aspect of PyTorch is a regular Python program under the full control of its user. We also explain how the careful and pragmatic implementation of the key components of its runtime enables them to work together to achieve compelling performance. We demonstrate the efficiency of individual subsystems, as well as the overall speed of PyTorch on several common benchmarks.",https://openalex.org/W2970971581,2019,Adam Paszke; Sam Gross; Francisco Massa,
A survey on Image Data Augmentation for Deep Learning,"Abstract Deep convolutional neural networks have performed remarkably well on many Computer Vision tasks. However, these networks are heavily reliant on big data to avoid overfitting. Overfitting refers to the phenomenon when a network learns a function with very high variance such as to perfectly model the training data. Unfortunately, many application domains do not have access to big data, such as medical image analysis. This survey focuses on Data Augmentation, a data-space solution to the problem of limited data. Data Augmentation encompasses a suite of techniques that enhance the size and quality of training datasets such that better Deep Learning models can be built using them. The image augmentation algorithms discussed in this survey include geometric transformations, color space augmentations, kernel filters, mixing images, random erasing, feature space augmentation, adversarial training, generative adversarial networks, neural style transfer, and meta-learning. The application of augmentation methods based on GANs are heavily covered in this survey. In addition to augmentation techniques, this paper will briefly discuss other characteristics of Data Augmentation such as test-time augmentation, resolution impact, final dataset size, and curriculum learning. This survey will present existing methods for Data Augmentation, promising developments, and meta-level decisions for implementing Data Augmentation. Readers will understand how Data Augmentation can improve the performance of their models and expand limited datasets to take advantage of the capabilities of big data.",https://openalex.org/W2954996726,2019,Connor Shorten; Taghi M. Khoshgoftaar,Florida Atlantic University
Deep Learning Face Attributes in the Wild,"Predicting face attributes in the wild is challenging due to complex face variations. We propose a novel deep learning framework for attribute prediction in the wild. It cascades two CNNs, LNet and ANet, which are fine-tuned jointly with attribute tags, but pre-trained differently. LNet is pre-trained by massive general object categories for face localization, while ANet is pre-trained by massive face identities for attribute prediction. This framework not only outperforms the state-of-the-art with a large margin, but also reveals valuable facts on learning face representation. (1) It shows how the performances of face localization (LNet) and attribute prediction (ANet) can be improved by different pre-training strategies. (2) It reveals that although the filters of LNet are fine-tuned only with image-level attribute tags, their response maps over entire images have strong indication of face locations. This fact enables training LNet for face localization with only image-level annotations, but without face bounding boxes or landmarks, which are required by all attribute recognition works. (3) It also demonstrates that the high-level hidden neurons of ANet automatically discover semantic concepts after pre-training with massive face identities, and such concepts are significantly enriched after fine-tuning with attribute tags. Each attribute can be well explained with a sparse linear combination of these concepts.",https://openalex.org/W1834627138,2015,Ziwei Liu; Ping Luo; Xiaogang Wang,Shenzhen Institutes of Advanced Technology; Chinese University of Hong Kong
